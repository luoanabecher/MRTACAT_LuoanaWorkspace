{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9106ef3-b532-41f2-a123-8ab55afc464d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Send Sensor Telemtry to RTI\n",
    "Stream data from the SensorData.csv file to RTI for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a0083-09c6-42cc-98d7-f99fab93d619",
   "metadata": {
    "cellStatus": "{\"Tyler Becker\":{\"session_start_time\":\"2025-06-23T16:09:16.0574031Z\",\"execution_start_time\":\"2025-06-23T16:09:26.1373393Z\",\"execution_finish_time\":\"2025-06-23T16:09:41.9005225Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Install the required package\n",
    "%pip install azure-eventhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e3896-3701-4511-ac94-459e00d2e179",
   "metadata": {
    "cellStatus": "{\"Tyler Becker\":{\"session_start_time\":null,\"execution_start_time\":\"2025-06-23T16:09:46.2135015Z\",\"execution_finish_time\":\"2025-06-23T16:09:46.6390698Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from azure.eventhub import EventHubConsumerClient, EventHubProducerClient,EventData\n",
    "import csv\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fed244-9614-4320-b354-c5d8b7fbda93",
   "metadata": {
    "cellStatus": "{\"Tyler Becker\":{\"session_start_time\":null,\"execution_start_time\":\"2025-06-23T16:09:46.641328Z\",\"execution_finish_time\":\"2025-06-23T16:09:46.9199919Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# DELETE LATER - THIS IS NOT NEEDED\n",
    "#from pyspark.sql import SparkSession\n",
    "#\n",
    "## Create a Spark session\n",
    "#spark = SparkSession.builder.appName(\"ReadCSV\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380aab2e-3940-43f7-9f71-876f0ccf8182",
   "metadata": {
    "cellStatus": "{\"Tyler Becker\":{\"session_start_time\":null,\"execution_start_time\":\"2025-06-23T16:09:46.9222025Z\",\"execution_finish_time\":\"2025-06-23T16:10:03.1023022Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell to ensure the file is accessible and has data - Optional to run.\n",
    "\n",
    "# Define the path to the CSV file in the Lakehouse\n",
    "file_path = \"abfss://Zava@onelake.dfs.fabric.microsoft.com/ZavaLakehouse.Lakehouse/Files/dtb_raw/SensorData.csv\"\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(file_path)\n",
    "\n",
    "# Show the first few rows\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c99f95-1fee-46be-ad23-ee2039f2a3d6",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Start the data generation below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39a514-514c-43ee-8f0d-c8c410b6ff33",
   "metadata": {
    "cellStatus": "{\"Tyler Becker\":{\"session_start_time\":null,\"execution_start_time\":\"2025-06-23T16:10:03.104662Z\",\"execution_finish_time\":\"2025-06-23T16:10:50.6124995Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1 Setup Connection Info\n",
    "connection_string = \"\";\n",
    "producer = EventHubProducerClient.from_connection_string(connection_string)\n",
    "\n",
    "# Step 2: Read CSV file from Lakehouse Files\n",
    "\n",
    "file_path = \"abfss://Zava@onelake.dfs.fabric.microsoft.com/ZavaLakehouse.Lakehouse/Files/dtb_raw/SensorData.csv\"\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(file_path)\n",
    "\n",
    "# Step 2: Convert DataFrame to JSON rows\n",
    "json_rows = df.toJSON().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea2234e-a6f8-4ae0-87fb-2f056038fd8d",
   "metadata": {
    "cellStatus": "{\"Tyler Becker\":{\"session_start_time\":null,\"execution_start_time\":\"2025-06-23T03:26:40.5717887Z\",\"execution_finish_time\":null,\"state\":\"submitted\",\"livy_statement_state\":\"running\",\"normalized_state\":\"running\"}}",
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Send 10 rows every 1 second and loop back to the beginning\n",
    "with producer:\n",
    "   while True:\n",
    "     for i in range(0, len(json_rows), 10):\n",
    "          batch = json_rows[i:i+10]\n",
    "          event_data_batch = [EventData(row) for row in batch]\n",
    "          producer.send_batch(event_data_batch)\n",
    "          # print(f\"Sent batch {i//10 + 1}\")\n",
    "          time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {},
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
